{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kevinsadi/StyleTerrain/blob/main/SG2_TERRAIN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jG7ZEc_982io"
      },
      "source": [
        "# StyleGAN2-ADA-PyTorch\n",
        "\n",
        "**Notes**\n",
        "* Training and Inference sections should be fairly stable. I’ll slowly add new features but it should work for most mainstream use cases.\n",
        "* Advanced Features are being documented toward the bottom of this notebook\n",
        "\n",
        "---\n",
        "\n",
        "If you find this notebook useful, consider signing up for my [Patreon](https://www.patreon.com/bustbright) or [YouTube channel](https://www.youtube.com/channel/UCaZuPdmZ380SFUMKHVsv_AA/join). You can also send me a one-time payment on [Venmo](https://venmo.com/Derrick-Schultz).\n",
        "\n",
        "---\n",
        "\n",
        "This Google Colab has last been modified by Kevin Sadi 4-6-2023"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vj4PG4_i9Alt"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qGEXPcFJ9UTY"
      },
      "source": [
        "Let’s start by checking to see what GPU we’ve been assigned. Ideally we get a V100, but a P100 is fine too. Other GPUs may lead to issues."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7VVICTCvd4mc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b058cc11-f11e-4c00-e777-f32112bbe7e4"
      },
      "source": [
        "!nvidia-smi -L"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU 0: Tesla T4 (UUID: GPU-cf46b561-1ef9-a3d2-a503-af4ebcd65bf5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rSV_HEoD9dxo"
      },
      "source": [
        "Next let’s connect our Google Drive account. This is optional but highly recommended."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IuVPuJmbigRs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4707dfde-f9f8-456e-ada5-e7e953bda81c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nTjVmfSK9CYa"
      },
      "source": [
        "## Install repo\n",
        "\n",
        "The next cell will install the StyleGAN repository in Google Drive. If you have already installed it it will just move into that folder. If you don’t have Google Drive connected it will just install the necessary code in Colab."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B8ADVNpBh8Ox",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "271ee0d4-b437-409b-eaeb-85e5df6427b2"
      },
      "source": [
        "import os\n",
        "!pip install gdown --upgrade\n",
        "\n",
        "if os.path.isdir(\"/content/drive/MyDrive/colab-sg2-ada-pytorch\"):\n",
        "    %cd \"/content/drive/MyDrive/colab-sg2-ada-pytorch/stylegan2-ada-pytorch\"\n",
        "elif os.path.isdir(\"/content/drive/\"):\n",
        "    #install script\n",
        "    %cd \"/content/drive/MyDrive/\"\n",
        "    !mkdir colab-sg2-ada-pytorch\n",
        "    %cd colab-sg2-ada-pytorch\n",
        "    !git clone https://github.com/dvschultz/stylegan2-ada-pytorch\n",
        "    %cd stylegan2-ada-pytorch\n",
        "    !mkdir downloads\n",
        "    !mkdir datasets\n",
        "    !mkdir pretrained\n",
        "    !gdown --id 1-5xZkD8ajXw1DdopTkH_rAoCsD72LhKU -O /content/drive/MyDrive/colab-sg2-ada-pytorch/stylegan2-ada-pytorch/pretrained/wikiart.pkl\n",
        "else:\n",
        "    !git clone https://github.com/dvschultz/stylegan2-ada-pytorch\n",
        "    %cd stylegan2-ada-pytorch\n",
        "    !mkdir downloads\n",
        "    !mkdir datasets\n",
        "    !mkdir pretrained\n",
        "    %cd pretrained\n",
        "    !gdown --id 1-5xZkD8ajXw1DdopTkH_rAoCsD72LhKU\n",
        "    %cd ../"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.9/dist-packages (4.6.6)\n",
            "Collecting gdown\n",
            "  Downloading gdown-4.7.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.9/dist-packages (from gdown) (4.11.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from gdown) (3.10.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.9/dist-packages (from gdown) (1.16.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from gdown) (4.65.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.9/dist-packages (from gdown) (2.27.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.9/dist-packages (from beautifulsoup4->gdown) (2.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests[socks]->gdown) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests[socks]->gdown) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests[socks]->gdown) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests[socks]->gdown) (2022.12.7)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.9/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Installing collected packages: gdown\n",
            "  Attempting uninstall: gdown\n",
            "    Found existing installation: gdown 4.6.6\n",
            "    Uninstalling gdown-4.6.6:\n",
            "      Successfully uninstalled gdown-4.6.6\n",
            "Successfully installed gdown-4.7.1\n",
            "/content/drive/MyDrive/colab-sg2-ada-pytorch/stylegan2-ada-pytorch\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Uninstall new JAX\n",
        "!pip uninstall jax jaxlib -y\n",
        "#GPU frontend\n",
        "!pip install \"jax[cuda11_cudnn805]==0.3.10\" -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html\n",
        "#CPU frontend\n",
        "#!pip install jax[cpu]==0.3.10\n",
        "#Downgrade Pytorch\n",
        "!pip uninstall torch torchvision -y\n",
        "!pip install torch==1.9.0+cu111 torchvision==0.10.0+cu111 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "!pip install timm==0.4.12 ftfy==6.1.1 ninja==1.10.2 opensimplex\n",
        "!pip install setuptools==59.5.0"
      ],
      "metadata": {
        "id": "jBeDEGqEbmLy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ae2cf5f-9e70-4f87-ebf2-4c517aa92218"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: jax 0.4.7\n",
            "Uninstalling jax-0.4.7:\n",
            "  Successfully uninstalled jax-0.4.7\n",
            "Found existing installation: jaxlib 0.4.7+cuda11.cudnn86\n",
            "Uninstalling jaxlib-0.4.7+cuda11.cudnn86:\n",
            "  Successfully uninstalled jaxlib-0.4.7+cuda11.cudnn86\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://storage.googleapis.com/jax-releases/jax_cuda_releases.html\n",
            "Collecting jax[cuda11_cudnn805]==0.3.10\n",
            "  Downloading jax-0.3.10.tar.gz (939 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m939.7/939.7 KB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.9/dist-packages (from jax[cuda11_cudnn805]==0.3.10) (1.4.0)\n",
            "Requirement already satisfied: numpy>=1.19 in /usr/local/lib/python3.9/dist-packages (from jax[cuda11_cudnn805]==0.3.10) (1.22.4)\n",
            "Requirement already satisfied: opt_einsum in /usr/local/lib/python3.9/dist-packages (from jax[cuda11_cudnn805]==0.3.10) (3.3.0)\n",
            "Requirement already satisfied: scipy>=1.2.1 in /usr/local/lib/python3.9/dist-packages (from jax[cuda11_cudnn805]==0.3.10) (1.10.1)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.9/dist-packages (from jax[cuda11_cudnn805]==0.3.10) (4.5.0)\n",
            "Collecting jaxlib==0.3.10+cuda11.cudnn805\n",
            "  Downloading https://storage.googleapis.com/jax-releases/cuda11/jaxlib-0.3.10%2Bcuda11.cudnn805-cp39-none-manylinux2014_x86_64.whl (175.7 MB)\n",
            "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[32m145.9/175.7 MB\u001b[0m \u001b[31m125.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0mInstalling collected packages: flatbuffers, jaxlib, jax\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 23.3.3\n",
            "    Uninstalling flatbuffers-23.3.3:\n",
            "      Successfully uninstalled flatbuffers-23.3.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.12.0 requires jax>=0.3.15, but you have jax 0.3.10 which is incompatible.\n",
            "orbax 0.1.7 requires jax>=0.4.6, but you have jax 0.3.10 which is incompatible.\n",
            "flax 0.6.8 requires jax>=0.4.2, but you have jax 0.3.10 which is incompatible.\n",
            "chex 0.1.7 requires jax>=0.4.6, but you have jax 0.3.10 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed flatbuffers-2.0.7 jax-0.3.10 jaxlib-0.3.10+cuda11.cudnn805\n",
            "Found existing installation: torch 2.0.0+cu118\n",
            "Uninstalling torch-2.0.0+cu118:\n",
            "  Successfully uninstalled torch-2.0.0+cu118\n",
            "Found existing installation: torchvision 0.15.1+cu118\n",
            "Uninstalling torchvision-0.15.1+cu118:\n",
            "  Successfully uninstalled torchvision-0.15.1+cu118\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==1.9.0+cu111\n",
            "  Downloading https://download.pytorch.org/whl/cu111/torch-1.9.0%2Bcu111-cp39-cp39-linux_x86_64.whl (2041.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 GB\u001b[0m \u001b[31m809.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchvision==0.10.0+cu111\n",
            "  Downloading https://download.pytorch.org/whl/cu111/torchvision-0.10.0%2Bcu111-cp39-cp39-linux_x86_64.whl (23.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.1/23.1 MB\u001b[0m \u001b[31m40.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch==1.9.0+cu111) (4.5.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from torchvision==0.10.0+cu111) (1.22.4)\n",
            "Requirement already satisfied: pillow>=5.3.0 in /usr/local/lib/python3.9/dist-packages (from torchvision==0.10.0+cu111) (8.4.0)\n",
            "Installing collected packages: torch, torchvision\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.15.1 requires torch==2.0.0, but you have torch 1.9.0+cu111 which is incompatible.\n",
            "torchdata 0.6.0 requires torch==2.0.0, but you have torch 1.9.0+cu111 which is incompatible.\n",
            "torchaudio 2.0.1+cu118 requires torch==2.0.0, but you have torch 1.9.0+cu111 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed torch-1.9.0+cu111 torchvision-0.10.0+cu111\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting timm==0.4.12\n",
            "  Downloading timm-0.4.12-py3-none-any.whl (376 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m377.0/377.0 KB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ftfy==6.1.1\n",
            "  Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 KB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ninja==1.10.2\n",
            "  Downloading ninja-1.10.2-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (108 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.1/108.1 KB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opensimplex\n",
            "  Downloading opensimplex-0.4.4-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.9/dist-packages (from timm==0.4.12) (0.10.0+cu111)\n",
            "Requirement already satisfied: torch>=1.4 in /usr/local/lib/python3.9/dist-packages (from timm==0.4.12) (1.9.0+cu111)\n",
            "Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.9/dist-packages (from ftfy==6.1.1) (0.2.6)\n",
            "Requirement already satisfied: numpy>=1.22 in /usr/local/lib/python3.9/dist-packages (from opensimplex) (1.22.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch>=1.4->timm==0.4.12) (4.5.0)\n",
            "Requirement already satisfied: pillow>=5.3.0 in /usr/local/lib/python3.9/dist-packages (from torchvision->timm==0.4.12) (8.4.0)\n",
            "Installing collected packages: ninja, opensimplex, ftfy, timm\n",
            "Successfully installed ftfy-6.1.1 ninja-1.10.2 opensimplex-0.4.4 timm-0.4.12\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting setuptools==59.5.0\n",
            "  Downloading setuptools-59.5.0-py3-none-any.whl (952 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m952.4/952.4 KB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: setuptools\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 67.6.1\n",
            "    Uninstalling setuptools-67.6.1:\n",
            "      Successfully uninstalled setuptools-67.6.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\n",
            "tensorflow 2.12.0 requires jax>=0.3.15, but you have jax 0.3.10 which is incompatible.\n",
            "cvxpy 1.3.1 requires setuptools>65.5.1, but you have setuptools 59.5.0 which is incompatible.\n",
            "arviz 0.15.1 requires setuptools>=60.0.0, but you have setuptools 59.5.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed setuptools-59.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9jMmUpn4DWRe"
      },
      "source": [
        "You probably don’t need to run this, but this will update your repo to the latest and greatest."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uV9bdvzeDRPd"
      },
      "source": [
        "%cd \"/content/drive/My Drive/colab-sg2-ada-pytorch/stylegan2-ada-pytorch\"\n",
        "!git config --global user.name \"test\"\n",
        "!git config --global user.email \"test@test.com\"\n",
        "!git fetch origin\n",
        "!git pull\n",
        "!git stash\n",
        "!git checkout origin/main -- train.py generate.py legacy.py closed_form_factorization.py flesh_digression.py apply_factor.py README.md calc_metrics.py training/stylegan2_multi.py training/training_loop.py util/utilgan.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZkcJ58P97Ls"
      },
      "source": [
        "## Dataset Preparation\n",
        "\n",
        "Upload a .zip of square images to the `datasets` folder. Previously you had to convert your model to .tfrecords. That’s no longer needed :)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5B-h6FpB9FaK"
      },
      "source": [
        "## Train model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bNc-3wTO-MUd"
      },
      "source": [
        "Below are a series of variables you need to set to run the training. You probably won’t need to touch most of them.\n",
        "\n",
        "* `dataset_path`: this is the path to your .zip file\n",
        "* `resume_from`: if you’re starting a new dataset I recommend `'ffhq1024'` or `'./pretrained/wikiart.pkl'`\n",
        "* `mirror_x` and `mirror_y`: Allow the dataset to use horizontal or vertical mirroring."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JV0W6yxP-UIn"
      },
      "source": [
        "#required: definitely edit these!\n",
        "dataset_path = '/content/drive/MyDrive/colab-sg2-ada-pytorch/stylegan2-ada-pytorch/datasets/clean_npy.zip'\n",
        "resume_from = './results/00036-clean_npy-mirror-11gb-gpu-gamma50-bg-resumecustom/network-snapshot-000352.pkl'\n",
        "aug_strength = 0.0\n",
        "train_count = 0\n",
        "mirror_x = True\n",
        "#mirror_y = False\n",
        "\n",
        "#optional: you might not need to edit these\n",
        "gamma_value = 50.0\n",
        "augs = 'bg'\n",
        "config = '11gb-gpu'\n",
        "snapshot_count = 4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py --gpus=1 --cfg=$config --metrics=None --outdir=./results --data=$dataset_path --resume=$resume_from --snap=$snapshot_count --augpipe=$augs --initstrength=$aug_strength --gamma=$gamma_value --mirror=$mirror_x --mirrory=False --nkimg=$train_count"
      ],
      "metadata": {
        "id": "JFhIMrfEhaEP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EL-M7WnnfMDI"
      },
      "source": [
        "!python train.py --gpus=1 --cfg=$config --metrics=None --outdir=./results --data=$dataset_path --snap=$snapshot_count --augpipe=$augs --initstrength=$aug_strength --gamma=$gamma_value --mirror=$mirror_x --mirrory=False --nkimg=$train_count"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RgvSvfyi_R_-"
      },
      "source": [
        "### Resume Training\n",
        "\n",
        "Once Colab has shutdown, you’ll need to resume your training. Reset the variables above, particularly the `resume_from` and `aug_strength` settings.\n",
        "\n",
        "1. Point `resume_from` to the last .pkl you trained (you’ll find these in the `results` folder)\n",
        "2. Update `aug_strength` to match the augment value of the last pkl file. Often you’ll see this in the console, but you may need to look at the `log.txt`. Updating this makes sure training stays as stable as possible.\n",
        "3. You may want to update `train_count` to keep track of your training progress.\n",
        "\n",
        "Once all of this has been reset, run that variable cell and the training command cell after it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VznRirOE5ENI"
      },
      "source": [
        "## Convert Legacy Model\n",
        "\n",
        "If you have an older version of a model (Tensorflow based StyleGAN, or Runway downloaded .pkl file) you’ll need to convert to the newest version. If you’ve trained in this notebook you do **not** need to use this cell.\n",
        "\n",
        "`--source`: path to model that you want to convert\n",
        "\n",
        "`--dest`: path and file name to convert to."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CzkP-Rww5Np9"
      },
      "source": [
        "!python legacy.py --source=/content/drive/MyDrive/runway.pkl --dest=/content/drive/MyDrive/colab-sg2-ada-pytorch/stylegan2-ada-pytorch/runway.pkl"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L6EtrPqL9ILk"
      },
      "source": [
        "## Testing/Inference\n",
        "\n",
        "Also known as \"Inference\", \"Evaluation\" or \"Testing\" the model. This is the process of usinng your trained model to generate new material, usually images or videos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mYdyfH0O8In_"
      },
      "source": [
        "### Generate Single Images\n",
        "\n",
        "`--network`: Make sure the `--network` argument points to your .pkl file. (My preferred method is to right click on the file in the Files pane to your left and choose `Copy Path`, then paste that into the argument after the `=` sign).\n",
        "\n",
        "`--seeds`: This allows you to choose random seeds from the model. Remember that our input to StyleGAN is a 512-dimensional array. These seeds will generate those 512 values. Each seed will generate a different, random array. The same seed value will also always generate the same random array, so we can later use it for other purposes like interpolation.\n",
        "\n",
        "`--truncation`: Truncation, well, truncates the latent space. This can have a subtle or dramatic affect on your images depending on the value you use. The smaller the number the more realistic your images should appear, but this will also affect diversity. Most people choose between 0.5 and 1.0, but technically it's infinite. \n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prefix = \"/content/drive/MyDrive/colab-sg2-ada-pytorch/stylegan2-ada-pytorch/results/\"\n",
        "network = prefix + \"00037-clean_npy-mirror-11gb-gpu-gamma50-bg-resumecustom/network-snapshot-000352.pkl\"\n",
        "!ls"
      ],
      "metadata": {
        "id": "17xqJhhRgz3y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c33e4411-75f0-4c60-e63a-ea3fd6802afb"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "apply_factor.py\t\t      Network_Blending_ADA_PT.ipynb\n",
            "blend_models.py\t\t      output\n",
            "calc_metrics.py\t\t      pbaylies_projector.py\n",
            "closed_form_factorization.py  pretrained\n",
            "combine_npz.py\t\t      projector.py\n",
            "datasets\t\t      __pycache__\n",
            "dataset_tool.py\t\t      README.md\n",
            "dnnlib\t\t\t      results\n",
            "Dockerfile\t\t      SG2-ADA-PT_AudioReactive+Pitch.ipynb\n",
            "docker_run.sh\t\t      SG2_ADA_PT_to_Rosinality.ipynb\n",
            "docs\t\t\t      SG2_ADA_PyTorch.ipynb\n",
            "downloads\t\t      StyleCLIP_playground.ipynb\n",
            "export_weights.py\t      StyleGAN2_CLIP_approach_v1.ipynb\n",
            "flesh_digression.py\t      style_mixing.py\n",
            "generate.py\t\t      torch_utils\n",
            "legacy.py\t\t      training\n",
            "LICENSE.txt\t\t      train.py\n",
            "metrics\t\t\t      util\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ninja opensimplex\n",
        "# lots of imports (for later routines)\n",
        "\n",
        "import os\n",
        "import re\n",
        "import subprocess\n",
        "from typing import List, Optional\n",
        "\n",
        "import dnnlib\n",
        "import numpy as np\n",
        "from numpy import linalg\n",
        "import PIL.Image\n",
        "import torch\n",
        "\n",
        "import legacy\n",
        "\n",
        "from opensimplex import OpenSimplex\n",
        "\n",
        "import functools\n",
        "import shutil\n",
        "import random\n",
        "import io\n",
        "\n",
        "import ipywidgets as widgets\n",
        "import IPython.display as display\n",
        "from IPython.display import clear_output\n",
        "from IPython.display import Image\n",
        "from ipywidgets import Label, Layout"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RsomU64Gkriw",
        "outputId": "d4953aae-0b66-414c-c325-44bbbbfa21df"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: ninja in /usr/local/lib/python3.9/dist-packages (1.10.2)\n",
            "Requirement already satisfied: opensimplex in /usr/local/lib/python3.9/dist-packages (0.4.4)\n",
            "Requirement already satisfied: numpy>=1.22 in /usr/local/lib/python3.9/dist-packages (from opensimplex) (1.22.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VYRXenMoZSHf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f66d4c3d-61f2-4c01-ecce-f236d6ee7ebc"
      },
      "source": [
        "!python generate.py --outdir=./output/images/high_dim --trunc=0.8 --seeds=0 --network=$network"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/colab-sg2-ada-pytorch/stylegan2-ada-pytorch/generate.py:59: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
            "  elif(len(seeds) is not 3):\n",
            "Loading networks from \"/content/drive/MyDrive/colab-sg2-ada-pytorch/stylegan2-ada-pytorch/results/00037-clean_npy-mirror-11gb-gpu-gamma50-bg-resumecustom/network-snapshot-000352.pkl\"...\n",
            "Generating image for seed 0 (0/1) ...\n",
            "Setting up PyTorch plugin \"bias_act_plugin\"... Done.\n",
            "Setting up PyTorch plugin \"upfirdn2d_plugin\"... Done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VjOTCWVonoVL"
      },
      "source": [
        "### Truncation Traversal\n",
        "\n",
        "Below you can take one seed and look at the changes to it across any truncation amount. -1 to 1 will be pretty realistic images, but the further out you get the weirder it gets.\n",
        "\n",
        "#### Options \n",
        "`--network`: Again, this should be the path to your .pkl file.\n",
        "\n",
        "`--seeds`: Pass this only one seed. Pick a favorite from your generated images.\n",
        "\n",
        "`--start`: Starting truncation value.\n",
        "\n",
        "`--stop`: Stopping truncation value. This should be larger than the start value. (Will probably break if its not).\n",
        "\n",
        "`--increment`: How much each frame should increment the truncation value. Make this really small if you want a long, slow interpolation. (stop-start/increment=total frames)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nyzdGr7OnrMG"
      },
      "source": [
        "!python generate.py --process=\"truncation\" --outdir=./output/trunc_images --start=-0.8 --stop=2.8 --increment=0.02 --seeds=470 --network=$network"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OSzj0igO8Lfu"
      },
      "source": [
        "### Interpolations\n",
        "\n",
        "Interpolation is the process of generating very small changes to a vector in order to make it appear animated from frame to frame.\n",
        "\n",
        "We’ll look at different examples of interpolation below.\n",
        "\n",
        "#### Options\n",
        "\n",
        "`--network`: path to your .pkl file\n",
        "\n",
        "`--interpolation`: Walk type defines the type of interpolation you want. In some cases it can also specify whether you want the z space or the w space.\n",
        "\n",
        "`--frames`: How many frames you want to produce. Use this to manage the length of your video.\n",
        "\n",
        "`--trunc`: truncation value"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OJSqafIzNwhx"
      },
      "source": [
        "#### Linear Interpolation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sqkiskly8S5_"
      },
      "source": [
        "!python generate.py --outdir=/content/out/video1-w-0.5/ --space=\"z\" --trunc=0.5 --process=\"interpolation\" --seeds=463,470 --network=/content/drive/MyDrive/stylegan2-transfer-models/mixed6k-network-snapshot-016470.pkl"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DCUEV3aO8s_X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba80f52a-3beb-455b-f284-f0c0f55d9aa1"
      },
      "source": [
        "!python generate.py --outdir=out/video1-w/ --space=\"w\" --trunc=1 --process=\"interpolation\" --seeds=85,265,297,849 --network=$network"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/colab-sg2-ada-pytorch/stylegan2-ada-pytorch/generate.py:59: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
            "  elif(len(seeds) is not 3):\n",
            "Loading networks from \"/content/drive/MyDrive/colab-sg2-ada-pytorch/stylegan2-ada-pytorch/results/00037-clean_npy-mirror-11gb-gpu-gamma50-bg-resumecustom/network-snapshot-000352.pkl\"...\n",
            "Setting up PyTorch plugin \"bias_act_plugin\"... Done.\n",
            "Generating image for frame 0/720 ...\n",
            "Setting up PyTorch plugin \"upfirdn2d_plugin\"... Done.\n",
            "Generating image for frame 1/720 ...\n",
            "Generating image for frame 2/720 ...\n",
            "Generating image for frame 3/720 ...\n",
            "Generating image for frame 4/720 ...\n",
            "Generating image for frame 5/720 ...\n",
            "Generating image for frame 6/720 ...\n",
            "Generating image for frame 7/720 ...\n",
            "Generating image for frame 8/720 ...\n",
            "Generating image for frame 9/720 ...\n",
            "Generating image for frame 10/720 ...\n",
            "Generating image for frame 11/720 ...\n",
            "Generating image for frame 12/720 ...\n",
            "Generating image for frame 13/720 ...\n",
            "Generating image for frame 14/720 ...\n",
            "Generating image for frame 15/720 ...\n",
            "Generating image for frame 16/720 ...\n",
            "Generating image for frame 17/720 ...\n",
            "Generating image for frame 18/720 ...\n",
            "Generating image for frame 19/720 ...\n",
            "Generating image for frame 20/720 ...\n",
            "Generating image for frame 21/720 ...\n",
            "Generating image for frame 22/720 ...\n",
            "Generating image for frame 23/720 ...\n",
            "Generating image for frame 24/720 ...\n",
            "Generating image for frame 25/720 ...\n",
            "Generating image for frame 26/720 ...\n",
            "Generating image for frame 27/720 ...\n",
            "Generating image for frame 28/720 ...\n",
            "Generating image for frame 29/720 ...\n",
            "Generating image for frame 30/720 ...\n",
            "Generating image for frame 31/720 ...\n",
            "Generating image for frame 32/720 ...\n",
            "Generating image for frame 33/720 ...\n",
            "Generating image for frame 34/720 ...\n",
            "Generating image for frame 35/720 ...\n",
            "Generating image for frame 36/720 ...\n",
            "Generating image for frame 37/720 ...\n",
            "Generating image for frame 38/720 ...\n",
            "Generating image for frame 39/720 ...\n",
            "Generating image for frame 40/720 ...\n",
            "Generating image for frame 41/720 ...\n",
            "Generating image for frame 42/720 ...\n",
            "Generating image for frame 43/720 ...\n",
            "Generating image for frame 44/720 ...\n",
            "Generating image for frame 45/720 ...\n",
            "Generating image for frame 46/720 ...\n",
            "Generating image for frame 47/720 ...\n",
            "Generating image for frame 48/720 ...\n",
            "Generating image for frame 49/720 ...\n",
            "Generating image for frame 50/720 ...\n",
            "Generating image for frame 51/720 ...\n",
            "Generating image for frame 52/720 ...\n",
            "Generating image for frame 53/720 ...\n",
            "Generating image for frame 54/720 ...\n",
            "Generating image for frame 55/720 ...\n",
            "Generating image for frame 56/720 ...\n",
            "Generating image for frame 57/720 ...\n",
            "Generating image for frame 58/720 ...\n",
            "Generating image for frame 59/720 ...\n",
            "Generating image for frame 60/720 ...\n",
            "Generating image for frame 61/720 ...\n",
            "Generating image for frame 62/720 ...\n",
            "Generating image for frame 63/720 ...\n",
            "Generating image for frame 64/720 ...\n",
            "Generating image for frame 65/720 ...\n",
            "Generating image for frame 66/720 ...\n",
            "Generating image for frame 67/720 ...\n",
            "Generating image for frame 68/720 ...\n",
            "Generating image for frame 69/720 ...\n",
            "Generating image for frame 70/720 ...\n",
            "Generating image for frame 71/720 ...\n",
            "Generating image for frame 72/720 ...\n",
            "Generating image for frame 73/720 ...\n",
            "Generating image for frame 74/720 ...\n",
            "Generating image for frame 75/720 ...\n",
            "Generating image for frame 76/720 ...\n",
            "Generating image for frame 77/720 ...\n",
            "Generating image for frame 78/720 ...\n",
            "Generating image for frame 79/720 ...\n",
            "Generating image for frame 80/720 ...\n",
            "Generating image for frame 81/720 ...\n",
            "Generating image for frame 82/720 ...\n",
            "Generating image for frame 83/720 ...\n",
            "Generating image for frame 84/720 ...\n",
            "Generating image for frame 85/720 ...\n",
            "Generating image for frame 86/720 ...\n",
            "Generating image for frame 87/720 ...\n",
            "Generating image for frame 88/720 ...\n",
            "Generating image for frame 89/720 ...\n",
            "Generating image for frame 90/720 ...\n",
            "Generating image for frame 91/720 ...\n",
            "Generating image for frame 92/720 ...\n",
            "Generating image for frame 93/720 ...\n",
            "Generating image for frame 94/720 ...\n",
            "Generating image for frame 95/720 ...\n",
            "Generating image for frame 96/720 ...\n",
            "Generating image for frame 97/720 ...\n",
            "Generating image for frame 98/720 ...\n",
            "Generating image for frame 99/720 ...\n",
            "Generating image for frame 100/720 ...\n",
            "Generating image for frame 101/720 ...\n",
            "Generating image for frame 102/720 ...\n",
            "Generating image for frame 103/720 ...\n",
            "Generating image for frame 104/720 ...\n",
            "Generating image for frame 105/720 ...\n",
            "Generating image for frame 106/720 ...\n",
            "Generating image for frame 107/720 ...\n",
            "Generating image for frame 108/720 ...\n",
            "Generating image for frame 109/720 ...\n",
            "Generating image for frame 110/720 ...\n",
            "Generating image for frame 111/720 ...\n",
            "Generating image for frame 112/720 ...\n",
            "Generating image for frame 113/720 ...\n",
            "Generating image for frame 114/720 ...\n",
            "Generating image for frame 115/720 ...\n",
            "Generating image for frame 116/720 ...\n",
            "Generating image for frame 117/720 ...\n",
            "Generating image for frame 118/720 ...\n",
            "Generating image for frame 119/720 ...\n",
            "Generating image for frame 120/720 ...\n",
            "Generating image for frame 121/720 ...\n",
            "Generating image for frame 122/720 ...\n",
            "Generating image for frame 123/720 ...\n",
            "Generating image for frame 124/720 ...\n",
            "Generating image for frame 125/720 ...\n",
            "Generating image for frame 126/720 ...\n",
            "Generating image for frame 127/720 ...\n",
            "Generating image for frame 128/720 ...\n",
            "Generating image for frame 129/720 ...\n",
            "Generating image for frame 130/720 ...\n",
            "Generating image for frame 131/720 ...\n",
            "Generating image for frame 132/720 ...\n",
            "Generating image for frame 133/720 ...\n",
            "Generating image for frame 134/720 ...\n",
            "Generating image for frame 135/720 ...\n",
            "Generating image for frame 136/720 ...\n",
            "Generating image for frame 137/720 ...\n",
            "Generating image for frame 138/720 ...\n",
            "Generating image for frame 139/720 ...\n",
            "Generating image for frame 140/720 ...\n",
            "Generating image for frame 141/720 ...\n",
            "Generating image for frame 142/720 ...\n",
            "Generating image for frame 143/720 ...\n",
            "Generating image for frame 144/720 ...\n",
            "Generating image for frame 145/720 ...\n",
            "Generating image for frame 146/720 ...\n",
            "Generating image for frame 147/720 ...\n",
            "Generating image for frame 148/720 ...\n",
            "Generating image for frame 149/720 ...\n",
            "Generating image for frame 150/720 ...\n",
            "Generating image for frame 151/720 ...\n",
            "Generating image for frame 152/720 ...\n",
            "Generating image for frame 153/720 ...\n",
            "Generating image for frame 154/720 ...\n",
            "Generating image for frame 155/720 ...\n",
            "Generating image for frame 156/720 ...\n",
            "Generating image for frame 157/720 ...\n",
            "Generating image for frame 158/720 ...\n",
            "Generating image for frame 159/720 ...\n",
            "Generating image for frame 160/720 ...\n",
            "Generating image for frame 161/720 ...\n",
            "Generating image for frame 162/720 ...\n",
            "Generating image for frame 163/720 ...\n",
            "Generating image for frame 164/720 ...\n",
            "Generating image for frame 165/720 ...\n",
            "Generating image for frame 166/720 ...\n",
            "Generating image for frame 167/720 ...\n",
            "Generating image for frame 168/720 ...\n",
            "Generating image for frame 169/720 ...\n",
            "Generating image for frame 170/720 ...\n",
            "Generating image for frame 171/720 ...\n",
            "Generating image for frame 172/720 ...\n",
            "Generating image for frame 173/720 ...\n",
            "Generating image for frame 174/720 ...\n",
            "Generating image for frame 175/720 ...\n",
            "Generating image for frame 176/720 ...\n",
            "Generating image for frame 177/720 ...\n",
            "Generating image for frame 178/720 ...\n",
            "Generating image for frame 179/720 ...\n",
            "Generating image for frame 180/720 ...\n",
            "Generating image for frame 181/720 ...\n",
            "Generating image for frame 182/720 ...\n",
            "Generating image for frame 183/720 ...\n",
            "Generating image for frame 184/720 ...\n",
            "Generating image for frame 185/720 ...\n",
            "Generating image for frame 186/720 ...\n",
            "Generating image for frame 187/720 ...\n",
            "Generating image for frame 188/720 ...\n",
            "Generating image for frame 189/720 ...\n",
            "Generating image for frame 190/720 ...\n",
            "Generating image for frame 191/720 ...\n",
            "Generating image for frame 192/720 ...\n",
            "Generating image for frame 193/720 ...\n",
            "Generating image for frame 194/720 ...\n",
            "Generating image for frame 195/720 ...\n",
            "Generating image for frame 196/720 ...\n",
            "Generating image for frame 197/720 ...\n",
            "Generating image for frame 198/720 ...\n",
            "Generating image for frame 199/720 ...\n",
            "Generating image for frame 200/720 ...\n",
            "Generating image for frame 201/720 ...\n",
            "Generating image for frame 202/720 ...\n",
            "Generating image for frame 203/720 ...\n",
            "Generating image for frame 204/720 ...\n",
            "Generating image for frame 205/720 ...\n",
            "Generating image for frame 206/720 ...\n",
            "Generating image for frame 207/720 ...\n",
            "Generating image for frame 208/720 ...\n",
            "Generating image for frame 209/720 ...\n",
            "Generating image for frame 210/720 ...\n",
            "Generating image for frame 211/720 ...\n",
            "Generating image for frame 212/720 ...\n",
            "Generating image for frame 213/720 ...\n",
            "Generating image for frame 214/720 ...\n",
            "Generating image for frame 215/720 ...\n",
            "Generating image for frame 216/720 ...\n",
            "Generating image for frame 217/720 ...\n",
            "Generating image for frame 218/720 ...\n",
            "Generating image for frame 219/720 ...\n",
            "Generating image for frame 220/720 ...\n",
            "Generating image for frame 221/720 ...\n",
            "Generating image for frame 222/720 ...\n",
            "Generating image for frame 223/720 ...\n",
            "Generating image for frame 224/720 ...\n",
            "Generating image for frame 225/720 ...\n",
            "Generating image for frame 226/720 ...\n",
            "Generating image for frame 227/720 ...\n",
            "Generating image for frame 228/720 ...\n",
            "Generating image for frame 229/720 ...\n",
            "Generating image for frame 230/720 ...\n",
            "Generating image for frame 231/720 ...\n",
            "Generating image for frame 232/720 ...\n",
            "Generating image for frame 233/720 ...\n",
            "Generating image for frame 234/720 ...\n",
            "Generating image for frame 235/720 ...\n",
            "Generating image for frame 236/720 ...\n",
            "Generating image for frame 237/720 ...\n",
            "Generating image for frame 238/720 ...\n",
            "Generating image for frame 239/720 ...\n",
            "Generating image for frame 240/720 ...\n",
            "Generating image for frame 241/720 ...\n",
            "Generating image for frame 242/720 ...\n",
            "Generating image for frame 243/720 ...\n",
            "Generating image for frame 244/720 ...\n",
            "Generating image for frame 245/720 ...\n",
            "Generating image for frame 246/720 ...\n",
            "Generating image for frame 247/720 ...\n",
            "Generating image for frame 248/720 ...\n",
            "Generating image for frame 249/720 ...\n",
            "Generating image for frame 250/720 ...\n",
            "Generating image for frame 251/720 ...\n",
            "Generating image for frame 252/720 ...\n",
            "Generating image for frame 253/720 ...\n",
            "Generating image for frame 254/720 ...\n",
            "Generating image for frame 255/720 ...\n",
            "Generating image for frame 256/720 ...\n",
            "Generating image for frame 257/720 ...\n",
            "Generating image for frame 258/720 ...\n",
            "Generating image for frame 259/720 ...\n",
            "Generating image for frame 260/720 ...\n",
            "Generating image for frame 261/720 ...\n",
            "Generating image for frame 262/720 ...\n",
            "Generating image for frame 263/720 ...\n",
            "Generating image for frame 264/720 ...\n",
            "Generating image for frame 265/720 ...\n",
            "Generating image for frame 266/720 ...\n",
            "Generating image for frame 267/720 ...\n",
            "Generating image for frame 268/720 ...\n",
            "Generating image for frame 269/720 ...\n",
            "Generating image for frame 270/720 ...\n",
            "Generating image for frame 271/720 ...\n",
            "Generating image for frame 272/720 ...\n",
            "Generating image for frame 273/720 ...\n",
            "Generating image for frame 274/720 ...\n",
            "Generating image for frame 275/720 ...\n",
            "Generating image for frame 276/720 ...\n",
            "Generating image for frame 277/720 ...\n",
            "Generating image for frame 278/720 ...\n",
            "Generating image for frame 279/720 ...\n",
            "Generating image for frame 280/720 ...\n",
            "Generating image for frame 281/720 ...\n",
            "Generating image for frame 282/720 ...\n",
            "Generating image for frame 283/720 ...\n",
            "Generating image for frame 284/720 ...\n",
            "Generating image for frame 285/720 ...\n",
            "Generating image for frame 286/720 ...\n",
            "Generating image for frame 287/720 ...\n",
            "Generating image for frame 288/720 ...\n",
            "Generating image for frame 289/720 ...\n",
            "Generating image for frame 290/720 ...\n",
            "Generating image for frame 291/720 ...\n",
            "Generating image for frame 292/720 ...\n",
            "Generating image for frame 293/720 ...\n",
            "Generating image for frame 294/720 ...\n",
            "Generating image for frame 295/720 ...\n",
            "Generating image for frame 296/720 ...\n",
            "Generating image for frame 297/720 ...\n",
            "Generating image for frame 298/720 ...\n",
            "Generating image for frame 299/720 ...\n",
            "Generating image for frame 300/720 ...\n",
            "Generating image for frame 301/720 ...\n",
            "Generating image for frame 302/720 ...\n",
            "Generating image for frame 303/720 ...\n",
            "Generating image for frame 304/720 ...\n",
            "Generating image for frame 305/720 ...\n",
            "Generating image for frame 306/720 ...\n",
            "Generating image for frame 307/720 ...\n",
            "Generating image for frame 308/720 ...\n",
            "Generating image for frame 309/720 ...\n",
            "Generating image for frame 310/720 ...\n",
            "Generating image for frame 311/720 ...\n",
            "Generating image for frame 312/720 ...\n",
            "Generating image for frame 313/720 ...\n",
            "Generating image for frame 314/720 ...\n",
            "Generating image for frame 315/720 ...\n",
            "Generating image for frame 316/720 ...\n",
            "Generating image for frame 317/720 ...\n",
            "Generating image for frame 318/720 ...\n",
            "Generating image for frame 319/720 ...\n",
            "Generating image for frame 320/720 ...\n",
            "Generating image for frame 321/720 ...\n",
            "Generating image for frame 322/720 ...\n",
            "Generating image for frame 323/720 ...\n",
            "Generating image for frame 324/720 ...\n",
            "Generating image for frame 325/720 ...\n",
            "Generating image for frame 326/720 ...\n",
            "Generating image for frame 327/720 ...\n",
            "Generating image for frame 328/720 ...\n",
            "Generating image for frame 329/720 ...\n",
            "Generating image for frame 330/720 ...\n",
            "Generating image for frame 331/720 ...\n",
            "Generating image for frame 332/720 ...\n",
            "Generating image for frame 333/720 ...\n",
            "Generating image for frame 334/720 ...\n",
            "Generating image for frame 335/720 ...\n",
            "Generating image for frame 336/720 ...\n",
            "Generating image for frame 337/720 ...\n",
            "Generating image for frame 338/720 ...\n",
            "Generating image for frame 339/720 ...\n",
            "Generating image for frame 340/720 ...\n",
            "Generating image for frame 341/720 ...\n",
            "Generating image for frame 342/720 ...\n",
            "Generating image for frame 343/720 ...\n",
            "Generating image for frame 344/720 ...\n",
            "Generating image for frame 345/720 ...\n",
            "Generating image for frame 346/720 ...\n",
            "Generating image for frame 347/720 ...\n",
            "Generating image for frame 348/720 ...\n",
            "Generating image for frame 349/720 ...\n",
            "Generating image for frame 350/720 ...\n",
            "Generating image for frame 351/720 ...\n",
            "Generating image for frame 352/720 ...\n",
            "Generating image for frame 353/720 ...\n",
            "Generating image for frame 354/720 ...\n",
            "Generating image for frame 355/720 ...\n",
            "Generating image for frame 356/720 ...\n",
            "Generating image for frame 357/720 ...\n",
            "Generating image for frame 358/720 ...\n",
            "Generating image for frame 359/720 ...\n",
            "Generating image for frame 360/720 ...\n",
            "Generating image for frame 361/720 ...\n",
            "Generating image for frame 362/720 ...\n",
            "Generating image for frame 363/720 ...\n",
            "Generating image for frame 364/720 ...\n",
            "Generating image for frame 365/720 ...\n",
            "Generating image for frame 366/720 ...\n",
            "Generating image for frame 367/720 ...\n",
            "Generating image for frame 368/720 ...\n",
            "Generating image for frame 369/720 ...\n",
            "Generating image for frame 370/720 ...\n",
            "Generating image for frame 371/720 ...\n",
            "Generating image for frame 372/720 ...\n",
            "Generating image for frame 373/720 ...\n",
            "Generating image for frame 374/720 ...\n",
            "Generating image for frame 375/720 ...\n",
            "Generating image for frame 376/720 ...\n",
            "Generating image for frame 377/720 ...\n",
            "Generating image for frame 378/720 ...\n",
            "Generating image for frame 379/720 ...\n",
            "Generating image for frame 380/720 ...\n",
            "Generating image for frame 381/720 ...\n",
            "Generating image for frame 382/720 ...\n",
            "Generating image for frame 383/720 ...\n",
            "Generating image for frame 384/720 ...\n",
            "Generating image for frame 385/720 ...\n",
            "Generating image for frame 386/720 ...\n",
            "Generating image for frame 387/720 ...\n",
            "Generating image for frame 388/720 ...\n",
            "Generating image for frame 389/720 ...\n",
            "Generating image for frame 390/720 ...\n",
            "Generating image for frame 391/720 ...\n",
            "Generating image for frame 392/720 ...\n",
            "Generating image for frame 393/720 ...\n",
            "Generating image for frame 394/720 ...\n",
            "Generating image for frame 395/720 ...\n",
            "Generating image for frame 396/720 ...\n",
            "Generating image for frame 397/720 ...\n",
            "Generating image for frame 398/720 ...\n",
            "Generating image for frame 399/720 ...\n",
            "Generating image for frame 400/720 ...\n",
            "Generating image for frame 401/720 ...\n",
            "Generating image for frame 402/720 ...\n",
            "Generating image for frame 403/720 ...\n",
            "Generating image for frame 404/720 ...\n",
            "Generating image for frame 405/720 ...\n",
            "Generating image for frame 406/720 ...\n",
            "Generating image for frame 407/720 ...\n",
            "Generating image for frame 408/720 ...\n",
            "Generating image for frame 409/720 ...\n",
            "Generating image for frame 410/720 ...\n",
            "Generating image for frame 411/720 ...\n",
            "Generating image for frame 412/720 ...\n",
            "Generating image for frame 413/720 ...\n",
            "Generating image for frame 414/720 ...\n",
            "Generating image for frame 415/720 ...\n",
            "Generating image for frame 416/720 ...\n",
            "Generating image for frame 417/720 ...\n",
            "Generating image for frame 418/720 ...\n",
            "Generating image for frame 419/720 ...\n",
            "Generating image for frame 420/720 ...\n",
            "Generating image for frame 421/720 ...\n",
            "Generating image for frame 422/720 ...\n",
            "Generating image for frame 423/720 ...\n",
            "Generating image for frame 424/720 ...\n",
            "Generating image for frame 425/720 ...\n",
            "Generating image for frame 426/720 ...\n",
            "Generating image for frame 427/720 ...\n",
            "Generating image for frame 428/720 ...\n",
            "Generating image for frame 429/720 ...\n",
            "Generating image for frame 430/720 ...\n",
            "Generating image for frame 431/720 ...\n",
            "Generating image for frame 432/720 ...\n",
            "Generating image for frame 433/720 ...\n",
            "Generating image for frame 434/720 ...\n",
            "Generating image for frame 435/720 ...\n",
            "Generating image for frame 436/720 ...\n",
            "Generating image for frame 437/720 ...\n",
            "Generating image for frame 438/720 ...\n",
            "Generating image for frame 439/720 ...\n",
            "Generating image for frame 440/720 ...\n",
            "Generating image for frame 441/720 ...\n",
            "Generating image for frame 442/720 ...\n",
            "Generating image for frame 443/720 ...\n",
            "Generating image for frame 444/720 ...\n",
            "Generating image for frame 445/720 ...\n",
            "Generating image for frame 446/720 ...\n",
            "Generating image for frame 447/720 ...\n",
            "Generating image for frame 448/720 ...\n",
            "Generating image for frame 449/720 ...\n",
            "Generating image for frame 450/720 ...\n",
            "Generating image for frame 451/720 ...\n",
            "Generating image for frame 452/720 ...\n",
            "Generating image for frame 453/720 ...\n",
            "Generating image for frame 454/720 ...\n",
            "Generating image for frame 455/720 ...\n",
            "Generating image for frame 456/720 ...\n",
            "Generating image for frame 457/720 ...\n",
            "Generating image for frame 458/720 ...\n",
            "Generating image for frame 459/720 ...\n",
            "Generating image for frame 460/720 ...\n",
            "Generating image for frame 461/720 ...\n",
            "Generating image for frame 462/720 ...\n",
            "Generating image for frame 463/720 ...\n",
            "Generating image for frame 464/720 ...\n",
            "Generating image for frame 465/720 ...\n",
            "Generating image for frame 466/720 ...\n",
            "Generating image for frame 467/720 ...\n",
            "Generating image for frame 468/720 ...\n",
            "Generating image for frame 469/720 ...\n",
            "Generating image for frame 470/720 ...\n",
            "Generating image for frame 471/720 ...\n",
            "Generating image for frame 472/720 ...\n",
            "Generating image for frame 473/720 ...\n",
            "Generating image for frame 474/720 ...\n",
            "Generating image for frame 475/720 ...\n",
            "Generating image for frame 476/720 ...\n",
            "Generating image for frame 477/720 ...\n",
            "Generating image for frame 478/720 ...\n",
            "Generating image for frame 479/720 ...\n",
            "Generating image for frame 480/720 ...\n",
            "Generating image for frame 481/720 ...\n",
            "Generating image for frame 482/720 ...\n",
            "Generating image for frame 483/720 ...\n",
            "Generating image for frame 484/720 ...\n",
            "Generating image for frame 485/720 ...\n",
            "Generating image for frame 486/720 ...\n",
            "Generating image for frame 487/720 ...\n",
            "Generating image for frame 488/720 ...\n",
            "Generating image for frame 489/720 ...\n",
            "Generating image for frame 490/720 ...\n",
            "Generating image for frame 491/720 ...\n",
            "Generating image for frame 492/720 ...\n",
            "Generating image for frame 493/720 ...\n",
            "Generating image for frame 494/720 ...\n",
            "Generating image for frame 495/720 ...\n",
            "Generating image for frame 496/720 ...\n",
            "Generating image for frame 497/720 ...\n",
            "Generating image for frame 498/720 ...\n",
            "Generating image for frame 499/720 ...\n",
            "Generating image for frame 500/720 ...\n",
            "Generating image for frame 501/720 ...\n",
            "Generating image for frame 502/720 ...\n",
            "Generating image for frame 503/720 ...\n",
            "Generating image for frame 504/720 ...\n",
            "Generating image for frame 505/720 ...\n",
            "Generating image for frame 506/720 ...\n",
            "Generating image for frame 507/720 ...\n",
            "Generating image for frame 508/720 ...\n",
            "Generating image for frame 509/720 ...\n",
            "Generating image for frame 510/720 ...\n",
            "Generating image for frame 511/720 ...\n",
            "Generating image for frame 512/720 ...\n",
            "Generating image for frame 513/720 ...\n",
            "Generating image for frame 514/720 ...\n",
            "Generating image for frame 515/720 ...\n",
            "Generating image for frame 516/720 ...\n",
            "Generating image for frame 517/720 ...\n",
            "Generating image for frame 518/720 ...\n",
            "Generating image for frame 519/720 ...\n",
            "Generating image for frame 520/720 ...\n",
            "Generating image for frame 521/720 ...\n",
            "Generating image for frame 522/720 ...\n",
            "Generating image for frame 523/720 ...\n",
            "Generating image for frame 524/720 ...\n",
            "Generating image for frame 525/720 ...\n",
            "Generating image for frame 526/720 ...\n",
            "Generating image for frame 527/720 ...\n",
            "Generating image for frame 528/720 ...\n",
            "Generating image for frame 529/720 ...\n",
            "Generating image for frame 530/720 ...\n",
            "Generating image for frame 531/720 ...\n",
            "Generating image for frame 532/720 ...\n",
            "Generating image for frame 533/720 ...\n",
            "Generating image for frame 534/720 ...\n",
            "Generating image for frame 535/720 ...\n",
            "Generating image for frame 536/720 ...\n",
            "Generating image for frame 537/720 ...\n",
            "Generating image for frame 538/720 ...\n",
            "Generating image for frame 539/720 ...\n",
            "Generating image for frame 540/720 ...\n",
            "Generating image for frame 541/720 ...\n",
            "Generating image for frame 542/720 ...\n",
            "Generating image for frame 543/720 ...\n",
            "Generating image for frame 544/720 ...\n",
            "Generating image for frame 545/720 ...\n",
            "Generating image for frame 546/720 ...\n",
            "Generating image for frame 547/720 ...\n",
            "Generating image for frame 548/720 ...\n",
            "Generating image for frame 549/720 ...\n",
            "Generating image for frame 550/720 ...\n",
            "Generating image for frame 551/720 ...\n",
            "Generating image for frame 552/720 ...\n",
            "Generating image for frame 553/720 ...\n",
            "Generating image for frame 554/720 ...\n",
            "Generating image for frame 555/720 ...\n",
            "Generating image for frame 556/720 ...\n",
            "Generating image for frame 557/720 ...\n",
            "Generating image for frame 558/720 ...\n",
            "Generating image for frame 559/720 ...\n",
            "Generating image for frame 560/720 ...\n",
            "Generating image for frame 561/720 ...\n",
            "Generating image for frame 562/720 ...\n",
            "Generating image for frame 563/720 ...\n",
            "Generating image for frame 564/720 ...\n",
            "Generating image for frame 565/720 ...\n",
            "Generating image for frame 566/720 ...\n",
            "Generating image for frame 567/720 ...\n",
            "Generating image for frame 568/720 ...\n",
            "Generating image for frame 569/720 ...\n",
            "Generating image for frame 570/720 ...\n",
            "Generating image for frame 571/720 ...\n",
            "Generating image for frame 572/720 ...\n",
            "Generating image for frame 573/720 ...\n",
            "Generating image for frame 574/720 ...\n",
            "Generating image for frame 575/720 ...\n",
            "Generating image for frame 576/720 ...\n",
            "Generating image for frame 577/720 ...\n",
            "Generating image for frame 578/720 ...\n",
            "Generating image for frame 579/720 ...\n",
            "Generating image for frame 580/720 ...\n",
            "Generating image for frame 581/720 ...\n",
            "Generating image for frame 582/720 ...\n",
            "Generating image for frame 583/720 ...\n",
            "Generating image for frame 584/720 ...\n",
            "Generating image for frame 585/720 ...\n",
            "Generating image for frame 586/720 ...\n",
            "Generating image for frame 587/720 ...\n",
            "Generating image for frame 588/720 ...\n",
            "Generating image for frame 589/720 ...\n",
            "Generating image for frame 590/720 ...\n",
            "Generating image for frame 591/720 ...\n",
            "Generating image for frame 592/720 ...\n",
            "Generating image for frame 593/720 ...\n",
            "Generating image for frame 594/720 ...\n",
            "Generating image for frame 595/720 ...\n",
            "Generating image for frame 596/720 ...\n",
            "Generating image for frame 597/720 ...\n",
            "Generating image for frame 598/720 ...\n",
            "Generating image for frame 599/720 ...\n",
            "Generating image for frame 600/720 ...\n",
            "Generating image for frame 601/720 ...\n",
            "Generating image for frame 602/720 ...\n",
            "Generating image for frame 603/720 ...\n",
            "Generating image for frame 604/720 ...\n",
            "Generating image for frame 605/720 ...\n",
            "Generating image for frame 606/720 ...\n",
            "Generating image for frame 607/720 ...\n",
            "Generating image for frame 608/720 ...\n",
            "Generating image for frame 609/720 ...\n",
            "Generating image for frame 610/720 ...\n",
            "Generating image for frame 611/720 ...\n",
            "Generating image for frame 612/720 ...\n",
            "Generating image for frame 613/720 ...\n",
            "Generating image for frame 614/720 ...\n",
            "Generating image for frame 615/720 ...\n",
            "Generating image for frame 616/720 ...\n",
            "Generating image for frame 617/720 ...\n",
            "Generating image for frame 618/720 ...\n",
            "Generating image for frame 619/720 ...\n",
            "Generating image for frame 620/720 ...\n",
            "Generating image for frame 621/720 ...\n",
            "Generating image for frame 622/720 ...\n",
            "Generating image for frame 623/720 ...\n",
            "Generating image for frame 624/720 ...\n",
            "Generating image for frame 625/720 ...\n",
            "Generating image for frame 626/720 ...\n",
            "Generating image for frame 627/720 ...\n",
            "Generating image for frame 628/720 ...\n",
            "Generating image for frame 629/720 ...\n",
            "Generating image for frame 630/720 ...\n",
            "Generating image for frame 631/720 ...\n",
            "Generating image for frame 632/720 ...\n",
            "Generating image for frame 633/720 ...\n",
            "Generating image for frame 634/720 ...\n",
            "Generating image for frame 635/720 ...\n",
            "Generating image for frame 636/720 ...\n",
            "Generating image for frame 637/720 ...\n",
            "Generating image for frame 638/720 ...\n",
            "Generating image for frame 639/720 ...\n",
            "Generating image for frame 640/720 ...\n",
            "Generating image for frame 641/720 ...\n",
            "Generating image for frame 642/720 ...\n",
            "Generating image for frame 643/720 ...\n",
            "Generating image for frame 644/720 ...\n",
            "Generating image for frame 645/720 ...\n",
            "Generating image for frame 646/720 ...\n",
            "Generating image for frame 647/720 ...\n",
            "Generating image for frame 648/720 ...\n",
            "Generating image for frame 649/720 ...\n",
            "Generating image for frame 650/720 ...\n",
            "Generating image for frame 651/720 ...\n",
            "Generating image for frame 652/720 ...\n",
            "Generating image for frame 653/720 ...\n",
            "Generating image for frame 654/720 ...\n",
            "Generating image for frame 655/720 ...\n",
            "Generating image for frame 656/720 ...\n",
            "Generating image for frame 657/720 ...\n",
            "Generating image for frame 658/720 ...\n",
            "Generating image for frame 659/720 ...\n",
            "Generating image for frame 660/720 ...\n",
            "Generating image for frame 661/720 ...\n",
            "Generating image for frame 662/720 ...\n",
            "Generating image for frame 663/720 ...\n",
            "Generating image for frame 664/720 ...\n",
            "Generating image for frame 665/720 ...\n",
            "Generating image for frame 666/720 ...\n",
            "Generating image for frame 667/720 ...\n",
            "Generating image for frame 668/720 ...\n",
            "Generating image for frame 669/720 ...\n",
            "Generating image for frame 670/720 ...\n",
            "Generating image for frame 671/720 ...\n",
            "Generating image for frame 672/720 ...\n",
            "Generating image for frame 673/720 ...\n",
            "Generating image for frame 674/720 ...\n",
            "Generating image for frame 675/720 ...\n",
            "Generating image for frame 676/720 ...\n",
            "Generating image for frame 677/720 ...\n",
            "Generating image for frame 678/720 ...\n",
            "Generating image for frame 679/720 ...\n",
            "Generating image for frame 680/720 ...\n",
            "Generating image for frame 681/720 ...\n",
            "Generating image for frame 682/720 ...\n",
            "Generating image for frame 683/720 ...\n",
            "Generating image for frame 684/720 ...\n",
            "Generating image for frame 685/720 ...\n",
            "Generating image for frame 686/720 ...\n",
            "Generating image for frame 687/720 ...\n",
            "Generating image for frame 688/720 ...\n",
            "Generating image for frame 689/720 ...\n",
            "Generating image for frame 690/720 ...\n",
            "Generating image for frame 691/720 ...\n",
            "Generating image for frame 692/720 ...\n",
            "Generating image for frame 693/720 ...\n",
            "Generating image for frame 694/720 ...\n",
            "Generating image for frame 695/720 ...\n",
            "Generating image for frame 696/720 ...\n",
            "Generating image for frame 697/720 ...\n",
            "Generating image for frame 698/720 ...\n",
            "Generating image for frame 699/720 ...\n",
            "Generating image for frame 700/720 ...\n",
            "Generating image for frame 701/720 ...\n",
            "Generating image for frame 702/720 ...\n",
            "Generating image for frame 703/720 ...\n",
            "Generating image for frame 704/720 ...\n",
            "Generating image for frame 705/720 ...\n",
            "Generating image for frame 706/720 ...\n",
            "Generating image for frame 707/720 ...\n",
            "Generating image for frame 708/720 ...\n",
            "Generating image for frame 709/720 ...\n",
            "Generating image for frame 710/720 ...\n",
            "Generating image for frame 711/720 ...\n",
            "Generating image for frame 712/720 ...\n",
            "Generating image for frame 713/720 ...\n",
            "Generating image for frame 714/720 ...\n",
            "Generating image for frame 715/720 ...\n",
            "Generating image for frame 716/720 ...\n",
            "Generating image for frame 717/720 ...\n",
            "Generating image for frame 718/720 ...\n",
            "Generating image for frame 719/720 ...\n",
            "ffmpeg version 4.2.7-0ubuntu0.1 Copyright (c) 2000-2022 the FFmpeg developers\n",
            "  built with gcc 9 (Ubuntu 9.4.0-1ubuntu1~20.04.1)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-avresample --disable-filter=resample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librsvg --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-nvenc --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
            "  libavutil      56. 31.100 / 56. 31.100\n",
            "  libavcodec     58. 54.100 / 58. 54.100\n",
            "  libavformat    58. 29.100 / 58. 29.100\n",
            "  libavdevice    58.  8.100 / 58.  8.100\n",
            "  libavfilter     7. 57.100 /  7. 57.100\n",
            "  libavresample   4.  0.  0 /  4.  0.  0\n",
            "  libswscale      5.  5.100 /  5.  5.100\n",
            "  libswresample   3.  5.100 /  3.  5.100\n",
            "  libpostproc    55.  5.100 / 55.  5.100\n",
            "Input #0, image2, from 'out/video1-w/frames/frame%04d.png':\n",
            "  Duration: 00:00:28.80, start: 0.000000, bitrate: N/A\n",
            "    Stream #0:0: Video: png, rgb24(pc), 128x128, 25 fps, 25 tbr, 25 tbn, 25 tbc\n",
            "Stream mapping:\n",
            "  Stream #0:0 -> #0:0 (png (native) -> h264 (libx264))\n",
            "Press [q] to stop, [?] for help\n",
            "\u001b[1;36m[libx264 @ 0x55fad59853c0] \u001b[0musing cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2\n",
            "\u001b[1;36m[libx264 @ 0x55fad59853c0] \u001b[0mprofile High, level 1.1\n",
            "\u001b[1;36m[libx264 @ 0x55fad59853c0] \u001b[0m264 - core 155 r2917 0a84d98 - H.264/MPEG-4 AVC codec - Copyleft 2003-2018 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=3 lookahead_threads=1 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=24 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=23.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n",
            "Output #0, mp4, to 'out/video1-w//interpolation-linear-seeds_85_265_297_849-24fps.mp4':\n",
            "  Metadata:\n",
            "    encoder         : Lavf58.29.100\n",
            "    Stream #0:0: Video: h264 (libx264) (avc1 / 0x31637661), yuv420p, 128x128, q=-1--1, 24 fps, 12288 tbn, 24 tbc\n",
            "    Metadata:\n",
            "      encoder         : Lavc58.54.100 libx264\n",
            "    Side data:\n",
            "      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: -1\n",
            "frame=  720 fps=556 q=-1.0 Lsize=      72kB time=00:00:29.87 bitrate=  19.9kbits/s speed=23.1x    \n",
            "video:68kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 6.269512%\n",
            "\u001b[1;36m[libx264 @ 0x55fad59853c0] \u001b[0mframe I:3     Avg QP:20.65  size:  2085\n",
            "\u001b[1;36m[libx264 @ 0x55fad59853c0] \u001b[0mframe P:688   Avg QP:22.23  size:    91\n",
            "\u001b[1;36m[libx264 @ 0x55fad59853c0] \u001b[0mframe B:29    Avg QP:26.24  size:    18\n",
            "\u001b[1;36m[libx264 @ 0x55fad59853c0] \u001b[0mconsecutive B-frames: 92.2%  7.2%  0.0%  0.6%\n",
            "\u001b[1;36m[libx264 @ 0x55fad59853c0] \u001b[0mmb I  I16..4: 34.4% 65.1%  0.5%\n",
            "\u001b[1;36m[libx264 @ 0x55fad59853c0] \u001b[0mmb P  I16..4:  0.1%  0.0%  0.0%  P16..4: 17.2%  2.2%  2.2%  0.0%  0.0%    skip:78.2%\n",
            "\u001b[1;36m[libx264 @ 0x55fad59853c0] \u001b[0mmb B  I16..4:  0.0%  0.0%  0.0%  B16..8:  8.4%  0.0%  0.0%  direct: 0.0%  skip:91.6%  L0: 6.5% L1:92.3% BI: 1.3%\n",
            "\u001b[1;36m[libx264 @ 0x55fad59853c0] \u001b[0m8x8 transform intra:47.0% inter:84.0%\n",
            "\u001b[1;36m[libx264 @ 0x55fad59853c0] \u001b[0mcoded y,uvDC,uvAC intra: 77.2% 74.6% 73.8% inter: 5.6% 7.2% 3.7%\n",
            "\u001b[1;36m[libx264 @ 0x55fad59853c0] \u001b[0mi16 v,h,dc,p: 100%  0%  0%  0%\n",
            "\u001b[1;36m[libx264 @ 0x55fad59853c0] \u001b[0mi8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 77%  8% 13%  1%  0%  0%  0%  0%  1%\n",
            "\u001b[1;36m[libx264 @ 0x55fad59853c0] \u001b[0mi4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 98%  0%  1%  0%  0%  0%  0%  0%  0%\n",
            "\u001b[1;36m[libx264 @ 0x55fad59853c0] \u001b[0mi8c dc,h,v,p: 10%  0% 90%  0%\n",
            "\u001b[1;36m[libx264 @ 0x55fad59853c0] \u001b[0mWeighted P-Frames: Y:0.0% UV:0.0%\n",
            "\u001b[1;36m[libx264 @ 0x55fad59853c0] \u001b[0mref P L0: 78.4% 14.9%  6.2%  0.6%\n",
            "\u001b[1;36m[libx264 @ 0x55fad59853c0] \u001b[0mref B L0: 91.7%  8.3%\n",
            "\u001b[1;36m[libx264 @ 0x55fad59853c0] \u001b[0mref B L1: 97.9%  2.1%\n",
            "\u001b[1;36m[libx264 @ 0x55fad59853c0] \u001b[0mkb/s:18.44\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yi3d7xzpN2Uj"
      },
      "source": [
        "#### Slerp Interpolation\n",
        "\n",
        "This gets a little heady, but technically linear interpolations are not the best in high-dimensional GANs. [This github link](https://github.com/soumith/dcgan.torch/issues/14) is one of the more popular explanations ad discussions.\n",
        "\n",
        "In reality I do not find a huge difference between linear and spherical interpolations (the difference in z- and w-space is enough in many cases), but I’ve implemented slerp here for anyone interested."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0-cUd3fB_kJ"
      },
      "source": [
        "!python generate.py --outdir=out/slerp-z/ --space=\"z\" --trunc=1 --process=\"interpolation\" --interpolation=\"slerp\" --seeds=85,265,297,849 --network=/content/stylegan2-ada-pytorch/pretrained/wikiart.pkl --frames=24"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PtnBIF75pcoY"
      },
      "source": [
        "!python generate.py --outdir=out/slerp-w/ --space=\"w\" --trunc=1 --process=\"interpolation\" --interpolation=\"slerp\" --seeds=85,265,297,849 --network=/content/stylegan2-ada-pytorch/pretrained/wikiart.pkl --frames=12"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uP1HsU_CPcF5"
      },
      "source": [
        "#### Noise Loop\n",
        "\n",
        "If you want to just make a random but fun interpolation of your model the noise loop is the way to go. It creates a random path thru the z space to show you a diverse set of images.\n",
        "\n",
        "`--interpolation=\"noiseloop\"`: set this to use the noise loop funtion\n",
        "\n",
        "`--diameter`: This controls how \"wide\" the loop is. Make it smaller to show a less diverse range of samples. Make it larger to cover a lot of samples. This plus `--frames` can help determine how fast the video feels.\n",
        "\n",
        "`--random_seed`: this allows you to change your starting place in the z space. Note: this value has nothing to do with the seeds you use to generate images. It just allows you to randomize your start point (and if you want to return to it you can use the same seed multiple times).\n",
        "\n",
        "Noise loops currently only work in z space."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gfR6DhfvN8b_"
      },
      "source": [
        "!python generate.py --outdir=out/video-noiseloop-0.9d/ --trunc=0.8 --process=\"interpolation\" --interpolation=\"noiseloop\" --diameter=0.9 --random_seed=100 --network=/content/stylegan2-ada-pytorch/pretrained/wikiart.pkl"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PkKFb-4CedOq"
      },
      "source": [
        "#### Circular Loop\n",
        "\n",
        "The noise loop is, well, noisy. This circular loop will feel much more even, while still providing a random loop.\n",
        "\n",
        "I recommend using a higher `--diameter` value than you do with noise loops. Something between `50.0` and `500.0` alongside `--frames` can help control speed and diversity."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ao62za9_QfOF"
      },
      "source": [
        "!python generate.py --outdir=out/video-circularloop/ --trunc=1 --process=\"interpolation\" --interpolation=\"circularloop\" --diameter=800.00 --frames=720 --random_seed=90 --network=/content/stylegan2-ada-pytorch/pretrained/wikiart.pkl"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qz-fVtzyAHg1"
      },
      "source": [
        "## Projection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ez7tXSpCA_zh"
      },
      "source": [
        "### Basic Projector\n",
        "\n",
        "*   `--target`: this is a path to the image file that you want to \"find\" in your model. This image must be the exact same size as your model.\n",
        "*   `--num-steps`: how many iterations the projctor should run for. Lower will mean less steps and less likelihood of a good projection. Higher will take longer but will likely produce better images.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p84CtZUGAKnR"
      },
      "source": [
        "!python projector.py --help"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80YTcjIQARWh"
      },
      "source": [
        "!python projector.py --network=/content/drive/MyDrive/colab-sg2-ada-pytorch/stylegan2-ada-pytorch/results/00023-chin-morris-mirror-11gb-gpu-gamma50-bg-resumecustom/network-snapshot-000304.pkl --outdir=/content/projector/ --target=/content/img005421_0.png --num-steps=200 --seed=0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hAxADbdpHHib"
      },
      "source": [
        "### Peter Baylies’ Projector"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iwS_ey9QF-nk"
      },
      "source": [
        "!python /content/stylegan2-ada-pytorch/pbaylies_projector.py --help"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-yj06MAABoLe"
      },
      "source": [
        "!python /content/stylegan2-ada-pytorch/pbaylies_projector.py --network=/content/ladiesblack.pkl --outdir=/content/projector-no-clip-006265-4-inv-3k/ --target-image=/content/img006265-4-inv.png --num-steps=3000 --use-clip=False --use-center=False --seed=99"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qywlaS5pgzyH"
      },
      "source": [
        "## Combine NPZ files together"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M2VooqrNfIpw"
      },
      "source": [
        "!python combine_npz.py --outdir=/content/npz --npzs='/content/projector-no-clip-006264-1-inv-3k/projector-no-clip-006264-1-inv-3k.npz,/content/projector-no-clip-006265-1-inv-3k/projector-no-clip-006265-1-inv-3k.npz,/content/projector-no-clip-006264-5-inv-3k/projector-no-clip-006264-5-inv-3k.npz,/content/projector-no-clip-006265-3-inv-3k/projector-no-clip-006265-3-inv-3k.npz,/content/projector-no-clip-006265-4-inv-3k/projector-no-clip-006265-4-inv-3k.npz,/content/projector-no-clip-006264-1-inv-3k/projector-no-clip-006264-1-inv-3k.npz'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uIqgl5nIHwpp"
      },
      "source": [
        "!python generate.py --help"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4cgezYN8Dsyh"
      },
      "source": [
        "!python generate.py --process=interpolation --interpolation=linear --easing=easeInOutQuad --space=w --network=/content/ladiesblack.pkl --outdir=/content/combined-proj/ --projected-w=/content/npz/combined.npz --frames=120"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lF7RCnSAsWrq"
      },
      "source": [
        "## Feature Extraction using Closed Form Factorization\n",
        "\n",
        "Feature Extraction is the process of finding “human readable” vectors in a StyleGAN model. For example, let’s say you wanted to find a vector that could open or close a mouth in a face model.\n",
        "\n",
        "The feature extractor tries to automate the procss of finding important vectors in your model.\n",
        "\n",
        "`--ckpt`: This is the path to your .pkl file. In other places its called `--network` (It’s a long story for why its name changed here)\n",
        "`--out`: path to save your output feature vector file. The file name must end in `.pt`!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_EKihY26OmTD"
      },
      "source": [
        "#### Non-Square outputs\n",
        "\n",
        "We can modify the model to output images that are not square. This isn’t as good as training a rectangular model, but with the right model it can still look nice.\n",
        "\n",
        "* `--size` size takes in a value of `xdim-ydim`. For example, to generate a 1920x1080 image use `1920-1080`\n",
        "* `--scale-type` This determines the padding style to apply in the additional space. There are four options: `pad`, `padside`, `symm`, and `symmside`. I recommend trying each one to see what works best with your images.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zuJxj-gdO3G0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92c7b628-8ae3-4774-cce8-d3b28c1b516b"
      },
      "source": [
        "!python generate.py --outdir=/content/out/images/ --trunc=0.7 --size=1820-1024 --scale-type=symm --seeds=0-499 --network=$network"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/colab-sg2-ada-pytorch/stylegan2-ada-pytorch/generate.py:59: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
            "  elif(len(seeds) is not 3):\n",
            "render custom size:  [1024, 1820]\n",
            "padding method: symm\n",
            "Loading networks from \"/content/drive/MyDrive/colab-sg2-ada-pytorch/stylegan2-ada-pytorch/results/00037-clean_npy-mirror-11gb-gpu-gamma50-bg-resumecustom/network-snapshot-000352.pkl\"...\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/colab-sg2-ada-pytorch/stylegan2-ada-pytorch/generate.py\", line 492, in <module>\n",
            "    generate_images() # pylint: disable=no-value-for-parameter\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/click/core.py\", line 1130, in __call__\n",
            "    return self.main(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/click/core.py\", line 1055, in main\n",
            "    rv = self.invoke(ctx)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/click/core.py\", line 1404, in invoke\n",
            "    return ctx.invoke(self.callback, **ctx.params)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/click/core.py\", line 760, in invoke\n",
            "    return __callback(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/click/decorators.py\", line 26, in new_func\n",
            "    return f(get_current_context(), *args, **kwargs)\n",
            "  File \"/content/drive/MyDrive/colab-sg2-ada-pytorch/stylegan2-ada-pytorch/generate.py\", line 408, in generate_images\n",
            "    G = legacy.load_network_pkl(f, custom=custom, **G_kwargs)['G_ema'].to(device) # type: ignore\n",
            "  File \"/content/drive/MyDrive/colab-sg2-ada-pytorch/stylegan2-ada-pytorch/legacy.py\", line 44, in load_network_pkl\n",
            "    G_ema = custom_generator(data, **ex_kwargs)\n",
            "  File \"/content/drive/MyDrive/colab-sg2-ada-pytorch/stylegan2-ada-pytorch/legacy.py\", line 148, in custom_generator\n",
            "    misc.copy_params_and_buffers(data['G_ema'], G_out, require_all=False)\n",
            "  File \"/content/drive/MyDrive/colab-sg2-ada-pytorch/stylegan2-ada-pytorch/torch_utils/misc.py\", line 160, in copy_params_and_buffers\n",
            "    tensor.copy_(src_tensors[name].detach()).requires_grad_(tensor.requires_grad)\n",
            "RuntimeError: The size of tensor a (256) must match the size of tensor b (512) at non-singleton dimension 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E_sGJowuPwwE"
      },
      "source": [
        "We can use these options for any image or video generation commands (excluding projection)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Hek6TFZCKD-"
      },
      "source": [
        "!python closed_form_factorization.py --out=/content/ladiesblack-cff.pt --ckpt=/content/ladiesblack.pkl"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WxLgeNeJRqFh"
      },
      "source": [
        "Once this cell is finished you’ll want to save that `.pt` file somewhere for reuse.\n",
        "\n",
        "This process just created the vctor values, but we need to test it on some seed values to determine what each vector actually changes. The `apply_factor.py` script does this.\n",
        "\n",
        "Arguments to try:\n",
        "\n",
        "\n",
        "*   `-i`: This stands for index. By default, the cell above will produce 512 vectors, so `-i` can be any value from 0 to 511. I recommend starting with a higher value.\n",
        "*   `-d`: This stands for degrees. This means how much change you want to see along th vector. I recommend a value between 5 and 10 to start with.\n",
        "*   `--seeds`: You know what these are by now right? :)\n",
        "*   `--ckpt`: path to your .pkl file\n",
        "*   `--video`: adding this to your argument will produce a video that animates your seeds along the vector path. I find it much easier to figure out what’s changing with an animation.\n",
        "*   `--output`: where to save the images/video\n",
        "*   `--space`: By default this will use the w space to reduce entanglement\n",
        "\n",
        "Lastly you need to add the path to the `.pt` file you made in th above cell. It’s weird, but you don’t need to add any arguments bfore it, just make sure its after `apply_factor.pt`\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dEDSl2VpCSJL"
      },
      "source": [
        "!python apply_factor.py -i 0 -d 10 --seeds 5,10 --ckpt /content/ladiesblack.pkl /content/ladiesblack-cff.pt --output /content/cff-vid/ --video"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mzwhrjGlTMZ3"
      },
      "source": [
        "That just produced images or video for a single vector, but there are 511 more! To generate every vector, you can uuse the cell below. Update any arguments you want, but don’t touch the `-i {i}` part.\n",
        "\n",
        "**Warning:** This takes a long time, especially if you have more than one seed value (pro tip: don’t usee more than one seed value)! Also, this will take up a good amount of space in Google Drive. You’ve been warned!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6aFj6mcKDmqk"
      },
      "source": [
        "for i in range(512):\n",
        "  !python apply_factor.py -i {i} -d 10 --seeds 177 --ckpt /content/drive/MyDrive/network-snapshot-008720.pkl /content/ladies-black-cff.pt --output /content/drive/MyDrive/ladiesblack-cff-17/ --video #--out_prefix 'ladiesblack-factor-{i}'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UVfmNV5JEcdp"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3VLRzmilrCf4"
      },
      "source": [
        "# Layer Manipulations\n",
        "\n",
        "The following scripts allow you to modify various resolution layers of the StyleGAN model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BDpQrBdevrDj"
      },
      "source": [
        "## Flesh Digressions\n",
        "\n",
        "Flesh Digressions works by manipulating the vectors in the base 4x4 layer. By doing this while leaving all the other layers untouched you can create a warping and twisting version of images from your model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BdvBNkMZv4MK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dda3cdec-4f7d-4427-d2bd-8a532a4a2f28"
      },
      "source": [
        "!python flesh_digression.py --pkl /content/colab-sg2-ada-pytorch/stylegan2-ada-pytorch/results/00005-images-mirror-11gb-gpu-gamma50-bg-resumecustom/network-snapshot-000320.pkl --psi 0.5 --seed 9999"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "flesh_digression.py:73: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
            "  if(len(seeds) is not 3):\n",
            "Traceback (most recent call last):\n",
            "  File \"flesh_digression.py\", line 15, in <module>\n",
            "    import moviepy.editor\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/moviepy/editor.py\", line 26, in <module>\n",
            "    imageio.plugins.ffmpeg.download()\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/imageio/plugins/ffmpeg.py\", line 37, in download\n",
            "    raise RuntimeError(\n",
            "RuntimeError: imageio.ffmpeg.download() has been deprecated. Use 'pip install imageio-ffmpeg' instead.'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G2TrnyvprL42"
      },
      "source": [
        "## Network Blending\n",
        "You can take two completely different models and combine them by splitting them at a specific resolution and combining the lower layers of one model and the higher layers of another.\n",
        "\n",
        "(Note: this tends to work best when one of the models is transfer learned from the other)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6pjl31Jwa4u"
      },
      "source": [
        "!python blend_models.py --lower_res_pkl /content/ffhq-pt.pkl --split_res 64 --higher_res_pkl /content/bone-bone-pt.pkl --output_path /content/ffhq-bonebone-split64.pkl"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "futaO6lBroVH"
      },
      "source": [
        "You can now take the output .pkl file and use that with any of the generation tools above."
      ]
    }
  ]
}